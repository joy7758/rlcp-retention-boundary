model:
  name: "rlcp-7B"
  size: "7B"

experiment:
  seed: 2026
  num_steps: 180
  retention_rates: [0.15, 0.12, 0.10, 0.08, 0.07, 0.06, 0.05, 0.04, 0.03, 0.02, 0.01]

attention:
  num_layers: 40
  num_heads: 16
  seq_len: 32

rlcp:
  enabled: true
  grad_reversal_enabled: true
  lambda_gr: 0.40
  beta:
    enabled: true
    schedule: "exponential"
    start: 0.10
    end: 1.20

flops:
  base_per_step: 2500000000000

output:
  root_dir: "results"
